{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/sh: line 0: cd: /home/kamil.kural/FdaPrecision: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!cd /home/kamil.kural/FdaPrecision Challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "current_path = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/kamil.kural/FdaPrecision Challenge'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import NuSVR, SVR\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "pd.options.display.precision = 15\n",
    "from collections import defaultdict\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as cat\n",
    "import time\n",
    "import datetime\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, RepeatedKFold, GroupKFold, GridSearchCV, train_test_split, TimeSeriesSplit, RepeatedStratifiedKFold\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn import linear_model\n",
    "import gc\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import eli5\n",
    "import shap\n",
    "from IPython.display import HTML\n",
    "import json\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from typing import List\n",
    "\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import json\n",
    "import gc\n",
    "from numba import jit\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostRegressor, CatBoostClassifier\n",
    "from sklearn import metrics\n",
    "from typing import Any\n",
    "from itertools import product\n",
    "pd.set_option('max_rows', 500)\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "import xgboost\n",
    "import lightgbm\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier,VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.tree import export_graphviz\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import torch \n",
    "import fastai\n",
    "import bayes_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.read_csv ('/home/kamil.kural/FdaPrecision Challenge/sc3_Phase1_CN_GE_FeatureMatrix.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=pd.read_csv ('/home/kamil.kural/FdaPrecision Challenge/sc3_Phase1_CN_GE_Outcome.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3=pd.read_csv ('/home/kamil.kural/FdaPrecision Challenge/sc3_Phase1_CN_GE_Phenotype.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df2,\n",
    "                    df1,\n",
    "                    left_index=True,\n",
    "                    right_index=True)\n",
    "df = pd.merge(df,\n",
    "                    df3,\n",
    "                    left_index=True,\n",
    "                    right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(['PATIENTID','PATIENTID_x','PATIENTID_y'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfnew=df[['PCMTD1', 'ARAP3','DYNLL2' ,'HAUS4', 'C4orf19', 'SMARCC2', 'CASTOR1' ,'PDCD4','SYCP2', 'ACBD4', 'SMU1' ,'SETD1A', '11p15.4', '9p24.1', '9p21.3' ,'20q11.21']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfnew= PCMTD1\n",
    "# ARAP3\n",
    "# DYNLL2\n",
    "# HAUS4\n",
    "# C4orf19\n",
    "# SMARCC2\n",
    "# CASTOR1\n",
    "# are the important features coming from Subchallenge 1.\n",
    "\n",
    "# The important features coming from Subchallenge 2 are \n",
    "# 11p15.4\n",
    "# 9p24.1\n",
    "# 9p21.3\n",
    "# 20q11.21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(166, 16)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfnew.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = [x for x in dfnew.columns if x not in ['SURVIVAL_STATUS']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1,\n",
       "       1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = dfnew[all_features], df['SURVIVAL_STATUS']\n",
    "labelencoder_y_1 = LabelEncoder()\n",
    "y = labelencoder_y_1.fit_transform(y)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42,stratify=df['SURVIVAL_STATUS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbounds = {\n",
    "    'learning_rate': (0.01, 1.0),\n",
    "    'n_estimators': (100,200),\n",
    "    'max_depth': (15,25),\n",
    "    'subsample': (0.1, 1.0),  # Change for big datasets\n",
    "    'colsample': (0.1, 1.0),  # Change for datasets with lots of features\n",
    "    'gamma': (0, 5),\n",
    "    'max_delta_step' : (0,5),\n",
    "    'min_child_weight' : (0,5),\n",
    "    'reg_alpha' : (0.1, 1),\n",
    "    'reg_lambda' : (0.1,1),\n",
    "    'scale_pos_weight' : (0.1, 1)}\n",
    " \n",
    "def xgboost_hyper_param(learning_rate,\n",
    "                        n_estimators,\n",
    "                        max_depth,\n",
    "                        subsample,\n",
    "                        colsample,\n",
    "                        gamma,\n",
    "                        max_delta_step,\n",
    "                        min_child_weight,\n",
    "                        reg_alpha,\n",
    "                        reg_lambda,\n",
    "                        scale_pos_weight):\n",
    " \n",
    "    max_depth = int(max_depth)\n",
    "    n_estimators = int(n_estimators)\n",
    " \n",
    "    clf = XGBClassifier(\n",
    "        max_depth=max_depth,\n",
    "        learning_rate=learning_rate,\n",
    "        n_estimators=n_estimators,\n",
    "        gamma=gamma,\n",
    "        max_delta_step=max_delta_step,\n",
    "        min_child_weight=min_child_weight,\n",
    "        reg_lambda=reg_lambda,\n",
    "        reg_alpha=reg_alpha,\n",
    "        scale_pos_weight=scale_pos_weight)\n",
    "    return np.mean(cross_val_score(clf, X, y, cv=10, scoring='accuracy',n_jobs=50))\n",
    " \n",
    " \n",
    "optimizer = BayesianOptimization(\n",
    "    f=xgboost_hyper_param,\n",
    "    pbounds=pbounds,\n",
    "    random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsample |   gamma   | learni... | max_de... | max_depth | min_ch... | n_esti... | reg_alpha | reg_la... | scale_... | subsample |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.796   \u001b[0m | \u001b[0m 0.4753  \u001b[0m | \u001b[0m 3.602   \u001b[0m | \u001b[0m 0.01011 \u001b[0m | \u001b[0m 1.512   \u001b[0m | \u001b[0m 16.47   \u001b[0m | \u001b[0m 0.4617  \u001b[0m | \u001b[0m 118.6   \u001b[0m | \u001b[0m 0.411   \u001b[0m | \u001b[0m 0.4571  \u001b[0m | \u001b[0m 0.5849  \u001b[0m | \u001b[0m 0.4773  \u001b[0m |\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m 0.8199  \u001b[0m | \u001b[95m 0.7167  \u001b[0m | \u001b[95m 1.022   \u001b[0m | \u001b[95m 0.8793  \u001b[0m | \u001b[95m 0.1369  \u001b[0m | \u001b[95m 21.7    \u001b[0m | \u001b[95m 2.087   \u001b[0m | \u001b[95m 155.9   \u001b[0m | \u001b[95m 0.2263  \u001b[0m | \u001b[95m 0.2783  \u001b[0m | \u001b[95m 0.8207  \u001b[0m | \u001b[95m 0.9714  \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.7544  \u001b[0m | \u001b[0m 0.3821  \u001b[0m | \u001b[0m 3.462   \u001b[0m | \u001b[0m 0.8776  \u001b[0m | \u001b[0m 4.473   \u001b[0m | \u001b[0m 15.85   \u001b[0m | \u001b[0m 0.1953  \u001b[0m | \u001b[0m 117.0   \u001b[0m | \u001b[0m 0.8903  \u001b[0m | \u001b[0m 0.1885  \u001b[0m | \u001b[0m 0.479   \u001b[0m | \u001b[0m 0.9621  \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.7846  \u001b[0m | \u001b[0m 0.5798  \u001b[0m | \u001b[0m 3.459   \u001b[0m | \u001b[0m 0.3224  \u001b[0m | \u001b[0m 3.433   \u001b[0m | \u001b[0m 23.35   \u001b[0m | \u001b[0m 0.09144 \u001b[0m | \u001b[0m 175.0   \u001b[0m | \u001b[0m 0.99    \u001b[0m | \u001b[0m 0.7733  \u001b[0m | \u001b[0m 0.3524  \u001b[0m | \u001b[0m 0.8104  \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.7493  \u001b[0m | \u001b[0m 0.1929  \u001b[0m | \u001b[0m 2.239   \u001b[0m | \u001b[0m 0.9095  \u001b[0m | \u001b[0m 1.468   \u001b[0m | \u001b[0m 17.88   \u001b[0m | \u001b[0m 0.6501  \u001b[0m | \u001b[0m 101.9   \u001b[0m | \u001b[0m 0.711   \u001b[0m | \u001b[0m 0.2905  \u001b[0m | \u001b[0m 0.339   \u001b[0m | \u001b[0m 0.5424  \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.464   \u001b[0m | \u001b[0m 0.148   \u001b[0m | \u001b[0m 2.871   \u001b[0m | \u001b[0m 0.1553  \u001b[0m | \u001b[0m 2.947   \u001b[0m | \u001b[0m 22.0    \u001b[0m | \u001b[0m 0.5117  \u001b[0m | \u001b[0m 141.4   \u001b[0m | \u001b[0m 0.725   \u001b[0m | \u001b[0m 0.4728  \u001b[0m | \u001b[0m 0.145   \u001b[0m | \u001b[0m 0.5823  \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.7555  \u001b[0m | \u001b[0m 0.6974  \u001b[0m | \u001b[0m 2.574   \u001b[0m | \u001b[0m 0.9451  \u001b[0m | \u001b[0m 2.933   \u001b[0m | \u001b[0m 24.03   \u001b[0m | \u001b[0m 0.6874  \u001b[0m | \u001b[0m 113.9   \u001b[0m | \u001b[0m 0.8267  \u001b[0m | \u001b[0m 0.4579  \u001b[0m | \u001b[0m 0.2488  \u001b[0m | \u001b[0m 0.9348  \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.7603  \u001b[0m | \u001b[0m 0.413   \u001b[0m | \u001b[0m 3.754   \u001b[0m | \u001b[0m 0.7287  \u001b[0m | \u001b[0m 4.417   \u001b[0m | \u001b[0m 21.24   \u001b[0m | \u001b[0m 3.755   \u001b[0m | \u001b[0m 134.9   \u001b[0m | \u001b[0m 0.3429  \u001b[0m | \u001b[0m 0.9063  \u001b[0m | \u001b[0m 0.4853  \u001b[0m | \u001b[0m 0.9684  \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.8147  \u001b[0m | \u001b[0m 0.6971  \u001b[0m | \u001b[0m 3.108   \u001b[0m | \u001b[0m 0.1236  \u001b[0m | \u001b[0m 4.747   \u001b[0m | \u001b[0m 19.5    \u001b[0m | \u001b[0m 2.892   \u001b[0m | \u001b[0m 140.8   \u001b[0m | \u001b[0m 0.3133  \u001b[0m | \u001b[0m 0.913   \u001b[0m | \u001b[0m 0.6163  \u001b[0m | \u001b[0m 0.1026  \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.7904  \u001b[0m | \u001b[0m 0.6554  \u001b[0m | \u001b[0m 1.633   \u001b[0m | \u001b[0m 0.5318  \u001b[0m | \u001b[0m 4.43    \u001b[0m | \u001b[0m 18.57   \u001b[0m | \u001b[0m 4.543   \u001b[0m | \u001b[0m 162.3   \u001b[0m | \u001b[0m 0.1142  \u001b[0m | \u001b[0m 0.9365  \u001b[0m | \u001b[0m 0.7218  \u001b[0m | \u001b[0m 0.9976  \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.7956  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 2.469   \u001b[0m | \u001b[0m 0.1645  \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 140.1   \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.7654  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 4.441e-1\u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 25.0    \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 200.0   \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.7956  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 25.0    \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 153.2   \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.2412  \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 200.0   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.7592  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 25.0    \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 169.3   \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.7721  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 111.8   \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.7779  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 19.29   \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 143.6   \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.7835  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 25.0    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 160.4   \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.7842  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 19.99   \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 125.1   \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.7721  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 25.0    \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 100.0   \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.7835  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 25.0    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 186.4   \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 0.7893  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 20.13   \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 140.1   \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 0.8074  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 17.77   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 162.8   \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 0.7842  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 15.05   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 131.1   \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m 0.2412  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 25.0    \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 185.0   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m 0.7835  \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 173.8   \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m 0.7835  \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 25.0    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 200.0   \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m 0.7835  \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 25.0    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 176.3   \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m 0.7011  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 22.57   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 168.9   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m 0.7897  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 25.0    \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 160.8   \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m |\n",
      "=============================================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "optimizer.maximize(init_points=10, n_iter=20, acq='ei')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': 0.8198529411764707,\n",
       " 'params': {'colsample': 0.7166975503570835,\n",
       "  'gamma': 1.0222612486575873,\n",
       "  'learning_rate': 0.879336262027036,\n",
       "  'max_delta_step': 0.13693796598963082,\n",
       "  'max_depth': 21.704675101784023,\n",
       "  'min_child_weight': 2.086524011835635,\n",
       "  'n_estimators': 155.86898284457516,\n",
       "  'reg_alpha': 0.2263482447357104,\n",
       "  'reg_lambda': 0.2782913401763909,\n",
       "  'scale_pos_weight': 0.820670111807983,\n",
       "  'subsample': 0.9714354181474578}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1=XGBClassifier(base_score=0.5, booster='gbtree', colsample=1,\n",
    "              gamma=1,\n",
    "              learning_rate=0.01, max_delta_step=0, max_depth=21,\n",
    "              min_child_weight=2, missing=None, n_estimators=200, n_jobs=20,\n",
    "              nthread=None, objective='binary:logistic', random_state=0,\n",
    "              reg_alpha=0.1, reg_lambda=0.1, scale_pos_weight=0.4, seed=None,\n",
    "              silent=None, subsample=1, verbosity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.2 s, sys: 4.02 ms, total: 1.2 s\n",
      "Wall time: 61.4 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample=1,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              gamma=1, learning_rate=0.01, max_delta_step=0, max_depth=21,\n",
       "              min_child_weight=2, missing=None, n_estimators=200, n_jobs=20,\n",
       "              nthread=None, objective='binary:logistic', random_state=0,\n",
       "              reg_alpha=0.1, reg_lambda=0.1, scale_pos_weight=0.4, seed=None,\n",
       "              silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_set = [(X_train, y_train), (X_test, y_test)]\n",
    "eval_metric = [\"auc\",\"error\"]\n",
    "%time model1.fit(X_train,y_train,eval_metric =eval_metric, eval_set=eval_set, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=model1.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity :  0.875\n",
      "Sensitivity :  0.9206349206349206\n",
      "Accuracy :  0.9096385542168675\n",
      "Confusion Matrix : \n",
      " [ 35   5  10 116]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "tn, fp, fn, tp = confusion_matrix(df['SURVIVAL_STATUS'], pred,labels=[0,1]).ravel()\n",
    "cm=confusion_matrix(df['SURVIVAL_STATUS'], pred,labels=[0,1]).ravel()\n",
    "total=sum(cm)\n",
    "accuracy=(tp+tn)/(tp+tn+fn+fp)\n",
    "sensitivity = tp/(tp+fn)\n",
    "specificity = tn/(tn+fp)\n",
    "print('Specificity : ', specificity)\n",
    "print('Sensitivity : ', sensitivity )\n",
    "print ('Accuracy : ', accuracy)\n",
    "print('Confusion Matrix : \\n', cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "pbounds = {\n",
    "    \n",
    "    'n_estimators': (100,500),\n",
    "    'max_depth': (20, 500),  # Change for big datasets\n",
    "    'min_samples_split': (0.1, 1),  # Change for datasets with lots of features\n",
    "                                }\n",
    " \n",
    "def rf_hyper_param(\n",
    "                        n_estimators,\n",
    "                        max_depth,\n",
    "                        min_samples_split,\n",
    "                        \n",
    "                        ):\n",
    " \n",
    "    max_depth = int(max_depth)\n",
    "    n_estimators = int(n_estimators)\n",
    " \n",
    "    clf = RandomForestClassifier(\n",
    "        max_depth=max_depth,\n",
    "        n_estimators=n_estimators,\n",
    "        min_samples_split=min_samples_split,\n",
    "        \n",
    "        )\n",
    "    return np.mean(cross_val_score(clf, X_train, y_train, cv=5, scoring='roc_auc',n_jobs=50))\n",
    " \n",
    " \n",
    "optimizer = BayesianOptimization(\n",
    "    f=rf_hyper_param,\n",
    "    pbounds=pbounds,\n",
    "    random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | max_depth | min_sa... | n_esti... |\n",
      "-------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 220.2   \u001b[0m | \u001b[0m 0.7483  \u001b[0m | \u001b[0m 100.0   \u001b[0m |\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m 0.8098  \u001b[0m | \u001b[95m 165.1   \u001b[0m | \u001b[95m 0.2321  \u001b[0m | \u001b[95m 136.9   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.8088  \u001b[0m | \u001b[0m 109.4   \u001b[0m | \u001b[0m 0.411   \u001b[0m | \u001b[0m 258.7   \u001b[0m |\n",
      "| \u001b[95m 4       \u001b[0m | \u001b[95m 0.8114  \u001b[0m | \u001b[95m 278.6   \u001b[0m | \u001b[95m 0.4773  \u001b[0m | \u001b[95m 374.1   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 118.1   \u001b[0m | \u001b[0m 0.8903  \u001b[0m | \u001b[0m 111.0   \u001b[0m |\n",
      "| \u001b[95m 6       \u001b[0m | \u001b[95m 0.814   \u001b[0m | \u001b[95m 341.8   \u001b[0m | \u001b[95m 0.4756  \u001b[0m | \u001b[95m 323.5   \u001b[0m |\n",
      "| \u001b[95m 7       \u001b[0m | \u001b[95m 0.8148  \u001b[0m | \u001b[95m 87.39   \u001b[0m | \u001b[95m 0.2783  \u001b[0m | \u001b[95m 420.3   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.8031  \u001b[0m | \u001b[0m 484.8   \u001b[0m | \u001b[0m 0.3821  \u001b[0m | \u001b[0m 376.9   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 440.7   \u001b[0m | \u001b[0m 0.9051  \u001b[0m | \u001b[0m 134.0   \u001b[0m |\n",
      "| \u001b[95m 10      \u001b[0m | \u001b[95m 0.8169  \u001b[0m | \u001b[95m 38.75   \u001b[0m | \u001b[95m 0.2528  \u001b[0m | \u001b[95m 451.3   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.8124  \u001b[0m | \u001b[0m 200.0   \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 219.4   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.816   \u001b[0m | \u001b[0m 369.6   \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 500.0   \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.8143  \u001b[0m | \u001b[0m 183.2   \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 500.0   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 500.0   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 500.0   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.8095  \u001b[0m | \u001b[0m 500.0   \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 269.0   \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.8124  \u001b[0m | \u001b[0m 161.5   \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 182.8   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.8105  \u001b[0m | \u001b[0m 20.0    \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 339.8   \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.8114  \u001b[0m | \u001b[0m 285.5   \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 500.0   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.8138  \u001b[0m | \u001b[0m 383.9   \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 402.1   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.8086  \u001b[0m | \u001b[0m 143.3   \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 328.6   \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 79.76   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 500.0   \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 0.814   \u001b[0m | \u001b[0m 20.0    \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 410.7   \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 0.7976  \u001b[0m | \u001b[0m 208.2   \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 447.0   \u001b[0m |\n",
      "| \u001b[95m 24      \u001b[0m | \u001b[95m 0.8188  \u001b[0m | \u001b[95m 441.1   \u001b[0m | \u001b[95m 0.1     \u001b[0m | \u001b[95m 317.7   \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m 0.8074  \u001b[0m | \u001b[0m 74.71   \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 320.8   \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m 0.8183  \u001b[0m | \u001b[0m 248.6   \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 300.4   \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m 0.8152  \u001b[0m | \u001b[0m 20.0    \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 263.4   \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m 0.8169  \u001b[0m | \u001b[0m 221.7   \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 500.0   \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m 0.8007  \u001b[0m | \u001b[0m 500.0   \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 324.7   \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m 0.804   \u001b[0m | \u001b[0m 183.6   \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 161.2   \u001b[0m |\n",
      "=============================================================\n"
     ]
    }
   ],
   "source": [
    "optimizer.maximize(init_points=10, n_iter=20, acq='ei')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest = RandomForestClassifier(criterion='gini',n_estimators=317,max_depth=441,min_samples_split=0.10,min_impurity_decrease=0.0,min_weight_fraction_leaf=0.0,max_features='auto', min_samples_leaf=8,random_state=0,oob_score=True,class_weight='balanced_subsample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='balanced_subsample',\n",
       "                       criterion='gini', max_depth=441, max_features='auto',\n",
       "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "                       min_impurity_split=None, min_samples_leaf=8,\n",
       "                       min_samples_split=0.1, min_weight_fraction_leaf=0.0,\n",
       "                       n_estimators=317, n_jobs=None, oob_score=True,\n",
       "                       random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomforest.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity :  0.825\n",
      "Sensitivity :  0.8809523809523809\n",
      "Accuracy :  0.8674698795180723\n",
      "Confusion Matrix : \n",
      " [ 33   7  15 111]\n"
     ]
    }
   ],
   "source": [
    "pred=randomforest.predict(X)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "tn, fp, fn, tp = confusion_matrix(df['SURVIVAL_STATUS'], pred,labels=[0,1]).ravel()\n",
    "cm=confusion_matrix(df['SURVIVAL_STATUS'], pred,labels=[0,1]).ravel()\n",
    "total=sum(cm)\n",
    "accuracy=(tp+tn)/(tp+tn+fn+fp)\n",
    "sensitivity = tp/(tp+fn)\n",
    "specificity = tn/(tn+fp)\n",
    "print('Specificity : ', specificity)\n",
    "print('Sensitivity : ', sensitivity )\n",
    "print ('Accuracy : ', accuracy)\n",
    "print('Confusion Matrix : \\n', cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=LogisticRegression(C=1.0, class_weight='balanced',\n",
       "                                          dual=False, fit_intercept=True,\n",
       "                                          intercept_scaling=1, l1_ratio=None,\n",
       "                                          max_iter=100, multi_class='warn',\n",
       "                                          n_jobs=50, penalty='l2',\n",
       "                                          random_state=None, solver='warn',\n",
       "                                          tol=0.0001, verbose=1000,\n",
       "                                          warm_start=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000] }\n",
    "clf = GridSearchCV(LogisticRegression(penalty='l2'), param_grid)\n",
    "GridSearchCV(cv=5,\n",
    "             estimator=LogisticRegression(C=1.0, intercept_scaling=1, class_weight='balanced' ,\n",
    "               dual=False, fit_intercept=True, penalty='l2', tol=0.0001,n_jobs=50,verbose= 1000),\n",
    "             param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                          fit_intercept=True,\n",
       "                                          intercept_scaling=1, l1_ratio=None,\n",
       "                                          max_iter=100, multi_class='warn',\n",
       "                                          n_jobs=None, penalty='l2',\n",
       "                                          random_state=None, solver='warn',\n",
       "                                          tol=0.0001, verbose=0,\n",
       "                                          warm_start=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.1}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params = clf.best_params_\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr1=LogisticRegression(C=0.01, class_weight='balanced', dual=False,\n",
    "                                          fit_intercept=True,\n",
    "                                          intercept_scaling=1, l1_ratio=None,\n",
    "                                          max_iter=300, multi_class='ovr',\n",
    "                                          n_jobs=20, penalty='l2',\n",
    "                                          random_state=None, solver='lbfgs',\n",
    "                                          tol=1e-4, verbose=1,\n",
    "                                          warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done   1 out of   1 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, class_weight='balanced', dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=300, multi_class='ovr', n_jobs=20, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=1,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr1.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity :  0.75\n",
      "Sensitivity :  0.7936507936507936\n",
      "Accuracy :  0.7831325301204819\n",
      "Confusion Matrix : \n",
      " [ 30  10  26 100]\n"
     ]
    }
   ],
   "source": [
    "pred=lr1.predict(X)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "tn, fp, fn, tp = confusion_matrix(df['SURVIVAL_STATUS'], pred,labels=[0,1]).ravel()\n",
    "cm=confusion_matrix(df['SURVIVAL_STATUS'], pred,labels=[0,1]).ravel()\n",
    "total=sum(cm)\n",
    "accuracy=(tp+tn)/(tp+tn+fn+fp)\n",
    "sensitivity = tp/(tp+fn)\n",
    "specificity = tn/(tn+fp)\n",
    "print('Specificity : ', specificity)\n",
    "print('Sensitivity : ', sensitivity )\n",
    "print ('Accuracy : ', accuracy)\n",
    "print('Confusion Matrix : \\n', cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_eval(num_leaves, feature_fraction, bagging_fraction, max_depth, lambda_l1, lambda_l2, min_split_gain, min_child_weight):\n",
    "    params = {'application':'binary','num_iterations':300, 'learning_rate':0.05, 'early_stopping_round':100, 'metric':'auc'}\n",
    "    params[\"num_leaves\"] = round(num_leaves)\n",
    "    params['feature_fraction'] = max(min(feature_fraction, 1), 0)\n",
    "    params['bagging_fraction'] = max(min(bagging_fraction, 1), 0)\n",
    "    params['max_depth'] = round(max_depth)\n",
    "    params['lambda_l1'] = max(lambda_l1, 0)\n",
    "    params['lambda_l2'] = max(lambda_l2, 0)\n",
    "    params['min_split_gain'] = min_split_gain\n",
    "    params['min_child_weight'] = min_child_weight\n",
    "    cv_result = lgb.cv(params, train_data, nfold=n_folds, seed=random_seed, stratified=True, verbose_eval =200, metrics=['auc'])\n",
    "    return max(cv_result['auc-mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbBO = BayesianOptimization(lgb_eval, {'num_leaves': (24, 45),\n",
    "                                        'feature_fraction': (0.1, 0.9),\n",
    "                                        'bagging_fraction': (0.8, 1),\n",
    "                                        'max_depth': (5, 8.99),\n",
    "                                        'lambda_l1': (0, 5),\n",
    "                                        'lambda_l2': (0, 3),\n",
    "                                        'min_split_gain': (0.001, 0.1),\n",
    "                                        'min_child_weight': (5, 50)}, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | baggin... | featur... | lambda_l1 | lambda_l2 | max_depth | min_ch... | min_sp... | num_le... |\n",
      "-------------------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.7189  \u001b[0m | \u001b[0m 0.9098  \u001b[0m | \u001b[0m 0.6722  \u001b[0m | \u001b[0m 3.014   \u001b[0m | \u001b[0m 1.635   \u001b[0m | \u001b[0m 13.47   \u001b[0m | \u001b[0m 6.813   \u001b[0m | \u001b[0m 0.04432 \u001b[0m | \u001b[0m 42.73   \u001b[0m |\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m 0.7439  \u001b[0m | \u001b[95m 0.9927  \u001b[0m | \u001b[95m 0.4068  \u001b[0m | \u001b[95m 3.959   \u001b[0m | \u001b[95m 1.587   \u001b[0m | \u001b[95m 16.36   \u001b[0m | \u001b[95m 9.33    \u001b[0m | \u001b[95m 0.008033\u001b[0m | \u001b[95m 25.83   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.7052  \u001b[0m | \u001b[0m 0.804   \u001b[0m | \u001b[0m 0.7661  \u001b[0m | \u001b[0m 3.891   \u001b[0m | \u001b[0m 2.61    \u001b[0m | \u001b[0m 24.57   \u001b[0m | \u001b[0m 8.192   \u001b[0m | \u001b[0m 0.04669 \u001b[0m | \u001b[0m 40.39   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.7232  \u001b[0m | \u001b[0m 0.8237  \u001b[0m | \u001b[0m 0.6119  \u001b[0m | \u001b[0m 0.7168  \u001b[0m | \u001b[0m 2.834   \u001b[0m | \u001b[0m 15.44   \u001b[0m | \u001b[0m 4.732   \u001b[0m | \u001b[0m 0.02719 \u001b[0m | \u001b[0m 40.26   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.7233  \u001b[0m | \u001b[0m 0.8912  \u001b[0m | \u001b[0m 0.5547  \u001b[0m | \u001b[0m 0.09395 \u001b[0m | \u001b[0m 1.853   \u001b[0m | \u001b[0m 17.24   \u001b[0m | \u001b[0m 6.552   \u001b[0m | \u001b[0m 0.09443 \u001b[0m | \u001b[0m 38.32   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.7396  \u001b[0m | \u001b[0m 0.8719  \u001b[0m | \u001b[0m 0.4496  \u001b[0m | \u001b[0m 3.488   \u001b[0m | \u001b[0m 0.1807  \u001b[0m | \u001b[0m 18.34   \u001b[0m | \u001b[0m 7.036   \u001b[0m | \u001b[0m 0.02183 \u001b[0m | \u001b[0m 26.71   \u001b[0m |\n",
      "| \u001b[95m 7       \u001b[0m | \u001b[95m 0.7699  \u001b[0m | \u001b[95m 0.8631  \u001b[0m | \u001b[95m 0.391   \u001b[0m | \u001b[95m 2.851   \u001b[0m | \u001b[95m 1.316   \u001b[0m | \u001b[95m 24.77   \u001b[0m | \u001b[95m 1.918   \u001b[0m | \u001b[95m 0.02168 \u001b[0m | \u001b[95m 27.39   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.7596  \u001b[0m | \u001b[0m 0.9306  \u001b[0m | \u001b[0m 0.3026  \u001b[0m | \u001b[0m 2.332   \u001b[0m | \u001b[0m 0.7333  \u001b[0m | \u001b[0m 8.179   \u001b[0m | \u001b[0m 1.993   \u001b[0m | \u001b[0m 0.06598 \u001b[0m | \u001b[0m 26.9    \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.7524  \u001b[0m | \u001b[0m 0.8393  \u001b[0m | \u001b[0m 0.395   \u001b[0m | \u001b[0m 4.105   \u001b[0m | \u001b[0m 0.2913  \u001b[0m | \u001b[0m 21.76   \u001b[0m | \u001b[0m 1.865   \u001b[0m | \u001b[0m 0.09767 \u001b[0m | \u001b[0m 33.84   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.7292  \u001b[0m | \u001b[0m 0.9954  \u001b[0m | \u001b[0m 0.5839  \u001b[0m | \u001b[0m 3.696   \u001b[0m | \u001b[0m 0.1176  \u001b[0m | \u001b[0m 10.66   \u001b[0m | \u001b[0m 2.082   \u001b[0m | \u001b[0m 0.03032 \u001b[0m | \u001b[0m 26.49   \u001b[0m |\n",
      "| \u001b[95m 11      \u001b[0m | \u001b[95m 0.784   \u001b[0m | \u001b[95m 1.0     \u001b[0m | \u001b[95m 0.1     \u001b[0m | \u001b[95m 0.0     \u001b[0m | \u001b[95m 0.0     \u001b[0m | \u001b[95m 5.0     \u001b[0m | \u001b[95m 1.0     \u001b[0m | \u001b[95m 0.1     \u001b[0m | \u001b[95m 45.0    \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 24.0    \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.7421  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 36.67   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 25.0    \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 24.0    \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 45.0    \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.784   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 25.0    \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 45.0    \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.7504  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 15.57   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 24.0    \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.7421  \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 24.0    \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.7421  \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 25.0    \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 24.0    \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.746   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 31.66   \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.7421  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 25.0    \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 45.0    \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 0.7323  \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 45.0    \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 25.0    \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 45.0    \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 0.7504  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 25.0    \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 35.94   \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 14.75   \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 33.34   \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m 0.7464  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 15.44   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 45.0    \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m 0.7436  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 24.0    \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m 0.7323  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 25.0    \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 39.66   \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m 0.722   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 25.0    \u001b[0m | \u001b[0m 6.019   \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 45.0    \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m 0.784   \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 37.02   \u001b[0m |\n",
      "=========================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "def bayes_parameter_opt_lgb(X_train, y_train, init_round=15, opt_round=25, n_folds=5, random_seed=0, n_estimators=10000, learning_rate=0.05, output_process=False):\n",
    "    # prepare data\n",
    "    train_data = lgb.Dataset(data=X_train, label=y_train)\n",
    "    # parameters\n",
    "    def lgb_eval(num_leaves, feature_fraction, bagging_fraction, max_depth, lambda_l1, lambda_l2, min_split_gain, min_child_weight,n_jobs=20):\n",
    "        params = {'application':'binary','num_iterations': n_estimators, 'learning_rate':learning_rate, 'early_stopping_round':100, 'metric':'auc'}\n",
    "        params[\"num_leaves\"] = int(round(num_leaves))\n",
    "        params['feature_fraction'] = max(min(feature_fraction, 1), 0)\n",
    "        params['bagging_fraction'] = max(min(bagging_fraction, 1), 0)\n",
    "        params['max_depth'] = int(round(max_depth))\n",
    "        params['lambda_l1'] = max(lambda_l1, 0)\n",
    "        params['lambda_l2'] = max(lambda_l2, 0)\n",
    "        params['min_split_gain'] = min_split_gain\n",
    "        params['min_child_weight'] = min_child_weight\n",
    "        cv_result = lgb.cv(params, train_data, nfold=n_folds, seed=random_seed, stratified=True, verbose_eval =200, metrics=['auc'])\n",
    "        return max(cv_result['auc-mean'])\n",
    "    # range \n",
    "    lgbBO = BayesianOptimization(lgb_eval, {'num_leaves': (24, 45),\n",
    "                                            'feature_fraction': (0.1, 0.9),\n",
    "                                            'bagging_fraction': (0.8, 1),\n",
    "                                            'max_depth': (5, 25),\n",
    "                                            'lambda_l1': (0, 5),\n",
    "                                            'lambda_l2': (0, 3),\n",
    "                                            'min_split_gain': (0.001, 0.1),\n",
    "                                            'min_child_weight': (1, 10)}, random_state=0)\n",
    "    # optimize\n",
    "    lgbBO.maximize(init_points=init_round, n_iter=opt_round)\n",
    "    \n",
    "    # output optimization process\n",
    "    if output_process==True: lgbBO.points_to_csv(\"bayes_opt_result.csv\")\n",
    "    \n",
    "    # return best parameters\n",
    "    \n",
    "\n",
    "opt_params = bayes_parameter_opt_lgb(X_train, y_train, init_round=10, opt_round=20, n_folds=5, random_seed=0, n_estimators=100, learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "model2=LGBMClassifier(num_leaves= 24, feature_fraction= 0.1, learning_rate= 0.01, bagging_fraction= 1, max_depth= 5,scale_pos_weight=0.5, min_child_weight= 1, n_estimators= 200, lambda_l1= 0, lambda_l2= 0, min_split_gain=0.1, n_jobs= 20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's auc: 0.706406\ttraining's binary_logloss: 0.552482\tvalid_1's auc: 0.778846\tvalid_1's binary_logloss: 0.544137\n",
      "[2]\ttraining's auc: 0.873437\ttraining's binary_logloss: 0.549609\tvalid_1's auc: 0.831731\tvalid_1's binary_logloss: 0.541677\n",
      "[3]\ttraining's auc: 0.926094\ttraining's binary_logloss: 0.546984\tvalid_1's auc: 0.829327\tvalid_1's binary_logloss: 0.540681\n",
      "[4]\ttraining's auc: 0.93125\ttraining's binary_logloss: 0.544528\tvalid_1's auc: 0.838942\tvalid_1's binary_logloss: 0.538528\n",
      "[5]\ttraining's auc: 0.938281\ttraining's binary_logloss: 0.542528\tvalid_1's auc: 0.848558\tvalid_1's binary_logloss: 0.537448\n",
      "[6]\ttraining's auc: 0.937969\ttraining's binary_logloss: 0.540066\tvalid_1's auc: 0.90625\tvalid_1's binary_logloss: 0.534215\n",
      "[7]\ttraining's auc: 0.940312\ttraining's binary_logloss: 0.537868\tvalid_1's auc: 0.877404\tvalid_1's binary_logloss: 0.533127\n",
      "[8]\ttraining's auc: 0.937187\ttraining's binary_logloss: 0.53632\tvalid_1's auc: 0.882212\tvalid_1's binary_logloss: 0.531914\n",
      "[9]\ttraining's auc: 0.941562\ttraining's binary_logloss: 0.535137\tvalid_1's auc: 0.877404\tvalid_1's binary_logloss: 0.530576\n",
      "[10]\ttraining's auc: 0.945937\ttraining's binary_logloss: 0.53259\tvalid_1's auc: 0.882212\tvalid_1's binary_logloss: 0.528466\n",
      "[11]\ttraining's auc: 0.944375\ttraining's binary_logloss: 0.530299\tvalid_1's auc: 0.877404\tvalid_1's binary_logloss: 0.527757\n",
      "[12]\ttraining's auc: 0.9425\ttraining's binary_logloss: 0.528161\tvalid_1's auc: 0.872596\tvalid_1's binary_logloss: 0.525931\n",
      "[13]\ttraining's auc: 0.944063\ttraining's binary_logloss: 0.526421\tvalid_1's auc: 0.867788\tvalid_1's binary_logloss: 0.525074\n",
      "[14]\ttraining's auc: 0.941875\ttraining's binary_logloss: 0.524284\tvalid_1's auc: 0.891827\tvalid_1's binary_logloss: 0.522327\n",
      "[15]\ttraining's auc: 0.942187\ttraining's binary_logloss: 0.522198\tvalid_1's auc: 0.877404\tvalid_1's binary_logloss: 0.521352\n",
      "[16]\ttraining's auc: 0.93875\ttraining's binary_logloss: 0.520862\tvalid_1's auc: 0.877404\tvalid_1's binary_logloss: 0.520386\n",
      "[17]\ttraining's auc: 0.941562\ttraining's binary_logloss: 0.519829\tvalid_1's auc: 0.887019\tvalid_1's binary_logloss: 0.51925\n",
      "[18]\ttraining's auc: 0.945937\ttraining's binary_logloss: 0.517543\tvalid_1's auc: 0.882212\tvalid_1's binary_logloss: 0.517415\n",
      "[19]\ttraining's auc: 0.942813\ttraining's binary_logloss: 0.515513\tvalid_1's auc: 0.862981\tvalid_1's binary_logloss: 0.51692\n",
      "[20]\ttraining's auc: 0.943438\ttraining's binary_logloss: 0.513626\tvalid_1's auc: 0.867788\tvalid_1's binary_logloss: 0.515347\n",
      "[21]\ttraining's auc: 0.945\ttraining's binary_logloss: 0.512088\tvalid_1's auc: 0.877404\tvalid_1's binary_logloss: 0.514662\n",
      "[22]\ttraining's auc: 0.9425\ttraining's binary_logloss: 0.510207\tvalid_1's auc: 0.887019\tvalid_1's binary_logloss: 0.512297\n",
      "[23]\ttraining's auc: 0.9425\ttraining's binary_logloss: 0.508348\tvalid_1's auc: 0.867788\tvalid_1's binary_logloss: 0.511513\n",
      "[24]\ttraining's auc: 0.94\ttraining's binary_logloss: 0.507181\tvalid_1's auc: 0.877404\tvalid_1's binary_logloss: 0.510739\n",
      "[25]\ttraining's auc: 0.941875\ttraining's binary_logloss: 0.506266\tvalid_1's auc: 0.877404\tvalid_1's binary_logloss: 0.509762\n",
      "[26]\ttraining's auc: 0.944688\ttraining's binary_logloss: 0.504191\tvalid_1's auc: 0.887019\tvalid_1's binary_logloss: 0.508148\n",
      "[27]\ttraining's auc: 0.944375\ttraining's binary_logloss: 0.50237\tvalid_1's auc: 0.862981\tvalid_1's binary_logloss: 0.507815\n",
      "[28]\ttraining's auc: 0.94375\ttraining's binary_logloss: 0.500683\tvalid_1's auc: 0.862981\tvalid_1's binary_logloss: 0.506442\n",
      "[29]\ttraining's auc: 0.944063\ttraining's binary_logloss: 0.499307\tvalid_1's auc: 0.877404\tvalid_1's binary_logloss: 0.505892\n",
      "[30]\ttraining's auc: 0.9425\ttraining's binary_logloss: 0.497631\tvalid_1's auc: 0.887019\tvalid_1's binary_logloss: 0.503832\n",
      "[31]\ttraining's auc: 0.943438\ttraining's binary_logloss: 0.495957\tvalid_1's auc: 0.862981\tvalid_1's binary_logloss: 0.503198\n",
      "[32]\ttraining's auc: 0.945625\ttraining's binary_logloss: 0.494792\tvalid_1's auc: 0.865385\tvalid_1's binary_logloss: 0.502014\n",
      "[33]\ttraining's auc: 0.946562\ttraining's binary_logloss: 0.493969\tvalid_1's auc: 0.884615\tvalid_1's binary_logloss: 0.501155\n",
      "[34]\ttraining's auc: 0.948438\ttraining's binary_logloss: 0.492067\tvalid_1's auc: 0.889423\tvalid_1's binary_logloss: 0.499714\n",
      "[35]\ttraining's auc: 0.9475\ttraining's binary_logloss: 0.490411\tvalid_1's auc: 0.865385\tvalid_1's binary_logloss: 0.4995\n",
      "[36]\ttraining's auc: 0.946875\ttraining's binary_logloss: 0.488886\tvalid_1's auc: 0.870192\tvalid_1's binary_logloss: 0.498284\n",
      "[37]\ttraining's auc: 0.947812\ttraining's binary_logloss: 0.487634\tvalid_1's auc: 0.865385\tvalid_1's binary_logloss: 0.497834\n",
      "[38]\ttraining's auc: 0.94625\ttraining's binary_logloss: 0.48612\tvalid_1's auc: 0.884615\tvalid_1's binary_logloss: 0.496009\n",
      "[39]\ttraining's auc: 0.947812\ttraining's binary_logloss: 0.484733\tvalid_1's auc: 0.875\tvalid_1's binary_logloss: 0.4956\n",
      "[40]\ttraining's auc: 0.95\ttraining's binary_logloss: 0.483655\tvalid_1's auc: 0.875\tvalid_1's binary_logloss: 0.494512\n",
      "[41]\ttraining's auc: 0.95\ttraining's binary_logloss: 0.482908\tvalid_1's auc: 0.879808\tvalid_1's binary_logloss: 0.493748\n",
      "[42]\ttraining's auc: 0.951875\ttraining's binary_logloss: 0.481149\tvalid_1's auc: 0.879808\tvalid_1's binary_logloss: 0.492451\n",
      "[43]\ttraining's auc: 0.951562\ttraining's binary_logloss: 0.479631\tvalid_1's auc: 0.870192\tvalid_1's binary_logloss: 0.492331\n",
      "[44]\ttraining's auc: 0.951562\ttraining's binary_logloss: 0.478238\tvalid_1's auc: 0.865385\tvalid_1's binary_logloss: 0.491242\n",
      "[45]\ttraining's auc: 0.95125\ttraining's binary_logloss: 0.477088\tvalid_1's auc: 0.875\tvalid_1's binary_logloss: 0.490878\n",
      "[46]\ttraining's auc: 0.951562\ttraining's binary_logloss: 0.475121\tvalid_1's auc: 0.884615\tvalid_1's binary_logloss: 0.489428\n",
      "[47]\ttraining's auc: 0.953125\ttraining's binary_logloss: 0.473849\tvalid_1's auc: 0.879808\tvalid_1's binary_logloss: 0.489104\n",
      "[48]\ttraining's auc: 0.955\ttraining's binary_logloss: 0.472845\tvalid_1's auc: 0.879808\tvalid_1's binary_logloss: 0.488095\n",
      "[49]\ttraining's auc: 0.956875\ttraining's binary_logloss: 0.472163\tvalid_1's auc: 0.879808\tvalid_1's binary_logloss: 0.487412\n",
      "[50]\ttraining's auc: 0.956875\ttraining's binary_logloss: 0.470529\tvalid_1's auc: 0.889423\tvalid_1's binary_logloss: 0.486236\n",
      "[51]\ttraining's auc: 0.955313\ttraining's binary_logloss: 0.469127\tvalid_1's auc: 0.879808\tvalid_1's binary_logloss: 0.486188\n",
      "[52]\ttraining's auc: 0.955\ttraining's binary_logloss: 0.467843\tvalid_1's auc: 0.884615\tvalid_1's binary_logloss: 0.485204\n",
      "[53]\ttraining's auc: 0.955937\ttraining's binary_logloss: 0.466778\tvalid_1's auc: 0.884615\tvalid_1's binary_logloss: 0.484909\n",
      "[54]\ttraining's auc: 0.9575\ttraining's binary_logloss: 0.464943\tvalid_1's auc: 0.889423\tvalid_1's binary_logloss: 0.483617\n",
      "[55]\ttraining's auc: 0.9575\ttraining's binary_logloss: 0.46377\tvalid_1's auc: 0.884615\tvalid_1's binary_logloss: 0.483363\n",
      "[56]\ttraining's auc: 0.95875\ttraining's binary_logloss: 0.462828\tvalid_1's auc: 0.884615\tvalid_1's binary_logloss: 0.48242\n",
      "[57]\ttraining's auc: 0.960625\ttraining's binary_logloss: 0.4622\tvalid_1's auc: 0.884615\tvalid_1's binary_logloss: 0.481804\n",
      "[58]\ttraining's auc: 0.960938\ttraining's binary_logloss: 0.460674\tvalid_1's auc: 0.889423\tvalid_1's binary_logloss: 0.480732\n",
      "[59]\ttraining's auc: 0.960938\ttraining's binary_logloss: 0.45929\tvalid_1's auc: 0.889423\tvalid_1's binary_logloss: 0.480373\n",
      "[60]\ttraining's auc: 0.959375\ttraining's binary_logloss: 0.458099\tvalid_1's auc: 0.889423\tvalid_1's binary_logloss: 0.479375\n",
      "[61]\ttraining's auc: 0.96125\ttraining's binary_logloss: 0.457256\tvalid_1's auc: 0.894231\tvalid_1's binary_logloss: 0.479287\n",
      "[62]\ttraining's auc: 0.961562\ttraining's binary_logloss: 0.455538\tvalid_1's auc: 0.894231\tvalid_1's binary_logloss: 0.478129\n",
      "[63]\ttraining's auc: 0.961562\ttraining's binary_logloss: 0.454373\tvalid_1's auc: 0.889423\tvalid_1's binary_logloss: 0.478107\n",
      "[64]\ttraining's auc: 0.961875\ttraining's binary_logloss: 0.453485\tvalid_1's auc: 0.884615\tvalid_1's binary_logloss: 0.477217\n",
      "[65]\ttraining's auc: 0.961875\ttraining's binary_logloss: 0.452907\tvalid_1's auc: 0.894231\tvalid_1's binary_logloss: 0.476658\n",
      "[66]\ttraining's auc: 0.961875\ttraining's binary_logloss: 0.451475\tvalid_1's auc: 0.899038\tvalid_1's binary_logloss: 0.475677\n",
      "[67]\ttraining's auc: 0.9625\ttraining's binary_logloss: 0.450182\tvalid_1's auc: 0.899038\tvalid_1's binary_logloss: 0.475376\n",
      "[68]\ttraining's auc: 0.961875\ttraining's binary_logloss: 0.449076\tvalid_1's auc: 0.899038\tvalid_1's binary_logloss: 0.474563\n",
      "[69]\ttraining's auc: 0.962187\ttraining's binary_logloss: 0.4483\tvalid_1's auc: 0.899038\tvalid_1's binary_logloss: 0.474511\n",
      "[70]\ttraining's auc: 0.961875\ttraining's binary_logloss: 0.446685\tvalid_1's auc: 0.899038\tvalid_1's binary_logloss: 0.473471\n",
      "[71]\ttraining's auc: 0.961875\ttraining's binary_logloss: 0.4456\tvalid_1's auc: 0.894231\tvalid_1's binary_logloss: 0.473482\n",
      "[72]\ttraining's auc: 0.9625\ttraining's binary_logloss: 0.444757\tvalid_1's auc: 0.894231\tvalid_1's binary_logloss: 0.472635\n",
      "[73]\ttraining's auc: 0.9625\ttraining's binary_logloss: 0.444221\tvalid_1's auc: 0.894231\tvalid_1's binary_logloss: 0.472124\n",
      "[74]\ttraining's auc: 0.962812\ttraining's binary_logloss: 0.442871\tvalid_1's auc: 0.899038\tvalid_1's binary_logloss: 0.471219\n",
      "[75]\ttraining's auc: 0.963125\ttraining's binary_logloss: 0.441707\tvalid_1's auc: 0.894231\tvalid_1's binary_logloss: 0.471172\n",
      "[76]\ttraining's auc: 0.9625\ttraining's binary_logloss: 0.440666\tvalid_1's auc: 0.894231\tvalid_1's binary_logloss: 0.470332\n",
      "[77]\ttraining's auc: 0.962812\ttraining's binary_logloss: 0.439948\tvalid_1's auc: 0.894231\tvalid_1's binary_logloss: 0.470311\n",
      "[78]\ttraining's auc: 0.962812\ttraining's binary_logloss: 0.438424\tvalid_1's auc: 0.894231\tvalid_1's binary_logloss: 0.469369\n",
      "[79]\ttraining's auc: 0.9625\ttraining's binary_logloss: 0.437279\tvalid_1's auc: 0.894231\tvalid_1's binary_logloss: 0.469306\n",
      "[80]\ttraining's auc: 0.962812\ttraining's binary_logloss: 0.436477\tvalid_1's auc: 0.894231\tvalid_1's binary_logloss: 0.4685\n",
      "[81]\ttraining's auc: 0.963437\ttraining's binary_logloss: 0.435978\tvalid_1's auc: 0.894231\tvalid_1's binary_logloss: 0.468028\n",
      "[82]\ttraining's auc: 0.964063\ttraining's binary_logloss: 0.4347\tvalid_1's auc: 0.894231\tvalid_1's binary_logloss: 0.467191\n",
      "[83]\ttraining's auc: 0.964063\ttraining's binary_logloss: 0.433597\tvalid_1's auc: 0.894231\tvalid_1's binary_logloss: 0.467181\n",
      "[84]\ttraining's auc: 0.964063\ttraining's binary_logloss: 0.432619\tvalid_1's auc: 0.894231\tvalid_1's binary_logloss: 0.466405\n",
      "[85]\ttraining's auc: 0.96375\ttraining's binary_logloss: 0.431943\tvalid_1's auc: 0.894231\tvalid_1's binary_logloss: 0.466461\n",
      "[86]\ttraining's auc: 0.964375\ttraining's binary_logloss: 0.430499\tvalid_1's auc: 0.894231\tvalid_1's binary_logloss: 0.465604\n",
      "[87]\ttraining's auc: 0.965313\ttraining's binary_logloss: 0.429123\tvalid_1's auc: 0.894231\tvalid_1's binary_logloss: 0.465119\n",
      "[88]\ttraining's auc: 0.96625\ttraining's binary_logloss: 0.428356\tvalid_1's auc: 0.894231\tvalid_1's binary_logloss: 0.464349\n",
      "[89]\ttraining's auc: 0.96625\ttraining's binary_logloss: 0.427887\tvalid_1's auc: 0.894231\tvalid_1's binary_logloss: 0.46391\n",
      "[90]\ttraining's auc: 0.965938\ttraining's binary_logloss: 0.426674\tvalid_1's auc: 0.894231\tvalid_1's binary_logloss: 0.463135\n",
      "[91]\ttraining's auc: 0.96625\ttraining's binary_logloss: 0.425628\tvalid_1's auc: 0.894231\tvalid_1's binary_logloss: 0.463154\n",
      "[92]\ttraining's auc: 0.966562\ttraining's binary_logloss: 0.424705\tvalid_1's auc: 0.894231\tvalid_1's binary_logloss: 0.462436\n",
      "[93]\ttraining's auc: 0.96625\ttraining's binary_logloss: 0.423969\tvalid_1's auc: 0.894231\tvalid_1's binary_logloss: 0.462661\n",
      "[94]\ttraining's auc: 0.966562\ttraining's binary_logloss: 0.422597\tvalid_1's auc: 0.894231\tvalid_1's binary_logloss: 0.46188\n",
      "[95]\ttraining's auc: 0.96625\ttraining's binary_logloss: 0.421284\tvalid_1's auc: 0.889423\tvalid_1's binary_logloss: 0.461441\n",
      "[96]\ttraining's auc: 0.966562\ttraining's binary_logloss: 0.42053\tvalid_1's auc: 0.889423\tvalid_1's binary_logloss: 0.460662\n",
      "[97]\ttraining's auc: 0.966562\ttraining's binary_logloss: 0.420087\tvalid_1's auc: 0.889423\tvalid_1's binary_logloss: 0.460252\n",
      "[98]\ttraining's auc: 0.966562\ttraining's binary_logloss: 0.418934\tvalid_1's auc: 0.894231\tvalid_1's binary_logloss: 0.459528\n",
      "[99]\ttraining's auc: 0.967187\ttraining's binary_logloss: 0.417955\tvalid_1's auc: 0.894231\tvalid_1's binary_logloss: 0.459078\n",
      "[100]\ttraining's auc: 0.967187\ttraining's binary_logloss: 0.417086\tvalid_1's auc: 0.894231\tvalid_1's binary_logloss: 0.458488\n",
      "[101]\ttraining's auc: 0.966562\ttraining's binary_logloss: 0.416393\tvalid_1's auc: 0.889423\tvalid_1's binary_logloss: 0.458727\n",
      "[102]\ttraining's auc: 0.966875\ttraining's binary_logloss: 0.415085\tvalid_1's auc: 0.889423\tvalid_1's binary_logloss: 0.458016\n",
      "[103]\ttraining's auc: 0.967187\ttraining's binary_logloss: 0.413829\tvalid_1's auc: 0.884615\tvalid_1's binary_logloss: 0.457618\n",
      "[104]\ttraining's auc: 0.967812\ttraining's binary_logloss: 0.413101\tvalid_1's auc: 0.884615\tvalid_1's binary_logloss: 0.45687\n",
      "[105]\ttraining's auc: 0.968125\ttraining's binary_logloss: 0.412681\tvalid_1's auc: 0.889423\tvalid_1's binary_logloss: 0.456484\n",
      "[106]\ttraining's auc: 0.967187\ttraining's binary_logloss: 0.411587\tvalid_1's auc: 0.889423\tvalid_1's binary_logloss: 0.455809\n",
      "[107]\ttraining's auc: 0.9675\ttraining's binary_logloss: 0.410631\tvalid_1's auc: 0.884615\tvalid_1's binary_logloss: 0.45587\n",
      "[108]\ttraining's auc: 0.967812\ttraining's binary_logloss: 0.409803\tvalid_1's auc: 0.884615\tvalid_1's binary_logloss: 0.455247\n",
      "[109]\ttraining's auc: 0.967812\ttraining's binary_logloss: 0.409146\tvalid_1's auc: 0.884615\tvalid_1's binary_logloss: 0.455499\n",
      "[110]\ttraining's auc: 0.967812\ttraining's binary_logloss: 0.407898\tvalid_1's auc: 0.884615\tvalid_1's binary_logloss: 0.454846\n",
      "[111]\ttraining's auc: 0.9675\ttraining's binary_logloss: 0.406695\tvalid_1's auc: 0.884615\tvalid_1's binary_logloss: 0.454485\n",
      "[112]\ttraining's auc: 0.968437\ttraining's binary_logloss: 0.405991\tvalid_1's auc: 0.879808\tvalid_1's binary_logloss: 0.453767\n",
      "[113]\ttraining's auc: 0.968437\ttraining's binary_logloss: 0.405591\tvalid_1's auc: 0.879808\tvalid_1's binary_logloss: 0.453401\n",
      "[114]\ttraining's auc: 0.969063\ttraining's binary_logloss: 0.404548\tvalid_1's auc: 0.879808\tvalid_1's binary_logloss: 0.452767\n",
      "[115]\ttraining's auc: 0.969688\ttraining's binary_logloss: 0.40366\tvalid_1's auc: 0.879808\tvalid_1's binary_logloss: 0.452368\n",
      "[116]\ttraining's auc: 0.969688\ttraining's binary_logloss: 0.402877\tvalid_1's auc: 0.879808\tvalid_1's binary_logloss: 0.451857\n",
      "[117]\ttraining's auc: 0.969375\ttraining's binary_logloss: 0.402255\tvalid_1's auc: 0.879808\tvalid_1's binary_logloss: 0.452118\n",
      "[118]\ttraining's auc: 0.969063\ttraining's binary_logloss: 0.401061\tvalid_1's auc: 0.884615\tvalid_1's binary_logloss: 0.451521\n",
      "[119]\ttraining's auc: 0.969375\ttraining's binary_logloss: 0.399905\tvalid_1's auc: 0.879808\tvalid_1's binary_logloss: 0.451195\n",
      "[120]\ttraining's auc: 0.97\ttraining's binary_logloss: 0.399223\tvalid_1's auc: 0.879808\tvalid_1's binary_logloss: 0.450501\n",
      "[121]\ttraining's auc: 0.97\ttraining's binary_logloss: 0.39884\tvalid_1's auc: 0.879808\tvalid_1's binary_logloss: 0.450154\n",
      "[122]\ttraining's auc: 0.970625\ttraining's binary_logloss: 0.397846\tvalid_1's auc: 0.879808\tvalid_1's binary_logloss: 0.449559\n",
      "[123]\ttraining's auc: 0.970625\ttraining's binary_logloss: 0.396962\tvalid_1's auc: 0.879808\tvalid_1's binary_logloss: 0.44965\n",
      "[124]\ttraining's auc: 0.970625\ttraining's binary_logloss: 0.396215\tvalid_1's auc: 0.879808\tvalid_1's binary_logloss: 0.449173\n",
      "[125]\ttraining's auc: 0.970625\ttraining's binary_logloss: 0.395623\tvalid_1's auc: 0.879808\tvalid_1's binary_logloss: 0.449441\n",
      "[126]\ttraining's auc: 0.970938\ttraining's binary_logloss: 0.39448\tvalid_1's auc: 0.879808\tvalid_1's binary_logloss: 0.448893\n",
      "[127]\ttraining's auc: 0.970938\ttraining's binary_logloss: 0.393368\tvalid_1's auc: 0.879808\tvalid_1's binary_logloss: 0.448596\n",
      "[128]\ttraining's auc: 0.97125\ttraining's binary_logloss: 0.392706\tvalid_1's auc: 0.879808\tvalid_1's binary_logloss: 0.447927\n",
      "[129]\ttraining's auc: 0.971562\ttraining's binary_logloss: 0.392339\tvalid_1's auc: 0.879808\tvalid_1's binary_logloss: 0.447594\n",
      "[130]\ttraining's auc: 0.970938\ttraining's binary_logloss: 0.391388\tvalid_1's auc: 0.879808\tvalid_1's binary_logloss: 0.447031\n",
      "[131]\ttraining's auc: 0.971562\ttraining's binary_logloss: 0.390576\tvalid_1's auc: 0.879808\tvalid_1's binary_logloss: 0.446673\n",
      "[132]\ttraining's auc: 0.97125\ttraining's binary_logloss: 0.389863\tvalid_1's auc: 0.879808\tvalid_1's binary_logloss: 0.44616\n",
      "[133]\ttraining's auc: 0.971562\ttraining's binary_logloss: 0.389299\tvalid_1's auc: 0.879808\tvalid_1's binary_logloss: 0.446434\n",
      "[134]\ttraining's auc: 0.97125\ttraining's binary_logloss: 0.388201\tvalid_1's auc: 0.879808\tvalid_1's binary_logloss: 0.44593\n",
      "[135]\ttraining's auc: 0.970938\ttraining's binary_logloss: 0.38713\tvalid_1's auc: 0.879808\tvalid_1's binary_logloss: 0.445662\n",
      "[136]\ttraining's auc: 0.971875\ttraining's binary_logloss: 0.386486\tvalid_1's auc: 0.879808\tvalid_1's binary_logloss: 0.445015\n",
      "[137]\ttraining's auc: 0.97125\ttraining's binary_logloss: 0.386134\tvalid_1's auc: 0.879808\tvalid_1's binary_logloss: 0.444696\n",
      "[138]\ttraining's auc: 0.97125\ttraining's binary_logloss: 0.385225\tvalid_1's auc: 0.879808\tvalid_1's binary_logloss: 0.444168\n",
      "[139]\ttraining's auc: 0.97125\ttraining's binary_logloss: 0.3844\tvalid_1's auc: 0.879808\tvalid_1's binary_logloss: 0.444281\n",
      "[140]\ttraining's auc: 0.971562\ttraining's binary_logloss: 0.38372\tvalid_1's auc: 0.879808\tvalid_1's binary_logloss: 0.443862\n",
      "[141]\ttraining's auc: 0.971562\ttraining's binary_logloss: 0.383181\tvalid_1's auc: 0.875\tvalid_1's binary_logloss: 0.444141\n",
      "[142]\ttraining's auc: 0.970938\ttraining's binary_logloss: 0.382127\tvalid_1's auc: 0.875\tvalid_1's binary_logloss: 0.443677\n",
      "[143]\ttraining's auc: 0.97125\ttraining's binary_logloss: 0.381095\tvalid_1's auc: 0.879808\tvalid_1's binary_logloss: 0.443434\n",
      "[144]\ttraining's auc: 0.9725\ttraining's binary_logloss: 0.38047\tvalid_1's auc: 0.879808\tvalid_1's binary_logloss: 0.442841\n",
      "[145]\ttraining's auc: 0.971562\ttraining's binary_logloss: 0.380131\tvalid_1's auc: 0.879808\tvalid_1's binary_logloss: 0.442533\n",
      "[146]\ttraining's auc: 0.971562\ttraining's binary_logloss: 0.379258\tvalid_1's auc: 0.879808\tvalid_1's binary_logloss: 0.442031\n",
      "[147]\ttraining's auc: 0.97125\ttraining's binary_logloss: 0.37851\tvalid_1's auc: 0.879808\tvalid_1's binary_logloss: 0.441704\n",
      "[148]\ttraining's auc: 0.97125\ttraining's binary_logloss: 0.377858\tvalid_1's auc: 0.879808\tvalid_1's binary_logloss: 0.441248\n",
      "[149]\ttraining's auc: 0.971875\ttraining's binary_logloss: 0.377186\tvalid_1's auc: 0.875\tvalid_1's binary_logloss: 0.441559\n",
      "[150]\ttraining's auc: 0.971562\ttraining's binary_logloss: 0.376172\tvalid_1's auc: 0.875\tvalid_1's binary_logloss: 0.441131\n",
      "[151]\ttraining's auc: 0.971875\ttraining's binary_logloss: 0.375175\tvalid_1's auc: 0.875\tvalid_1's binary_logloss: 0.440911\n",
      "[152]\ttraining's auc: 0.972812\ttraining's binary_logloss: 0.374565\tvalid_1's auc: 0.879808\tvalid_1's binary_logloss: 0.440336\n",
      "[153]\ttraining's auc: 0.972187\ttraining's binary_logloss: 0.374238\tvalid_1's auc: 0.879808\tvalid_1's binary_logloss: 0.440041\n",
      "[154]\ttraining's auc: 0.972187\ttraining's binary_logloss: 0.373403\tvalid_1's auc: 0.879808\tvalid_1's binary_logloss: 0.439567\n",
      "[155]\ttraining's auc: 0.972812\ttraining's binary_logloss: 0.372627\tvalid_1's auc: 0.875\tvalid_1's binary_logloss: 0.439698\n",
      "[156]\ttraining's auc: 0.972187\ttraining's binary_logloss: 0.372005\tvalid_1's auc: 0.875\tvalid_1's binary_logloss: 0.439328\n",
      "[157]\ttraining's auc: 0.9725\ttraining's binary_logloss: 0.37136\tvalid_1's auc: 0.870192\tvalid_1's binary_logloss: 0.439637\n",
      "[158]\ttraining's auc: 0.972187\ttraining's binary_logloss: 0.370384\tvalid_1's auc: 0.870192\tvalid_1's binary_logloss: 0.439243\n",
      "[159]\ttraining's auc: 0.972187\ttraining's binary_logloss: 0.369422\tvalid_1's auc: 0.870192\tvalid_1's binary_logloss: 0.439042\n",
      "[160]\ttraining's auc: 0.973125\ttraining's binary_logloss: 0.368824\tvalid_1's auc: 0.870192\tvalid_1's binary_logloss: 0.438485\n",
      "[161]\ttraining's auc: 0.972187\ttraining's binary_logloss: 0.368509\tvalid_1's auc: 0.875\tvalid_1's binary_logloss: 0.438198\n",
      "[162]\ttraining's auc: 0.972187\ttraining's binary_logloss: 0.367706\tvalid_1's auc: 0.875\tvalid_1's binary_logloss: 0.437747\n",
      "[163]\ttraining's auc: 0.972812\ttraining's binary_logloss: 0.366957\tvalid_1's auc: 0.870192\tvalid_1's binary_logloss: 0.437887\n",
      "[164]\ttraining's auc: 0.9725\ttraining's binary_logloss: 0.366357\tvalid_1's auc: 0.870192\tvalid_1's binary_logloss: 0.437477\n",
      "[165]\ttraining's auc: 0.9725\ttraining's binary_logloss: 0.365738\tvalid_1's auc: 0.870192\tvalid_1's binary_logloss: 0.437786\n",
      "[166]\ttraining's auc: 0.972187\ttraining's binary_logloss: 0.364798\tvalid_1's auc: 0.870192\tvalid_1's binary_logloss: 0.437419\n",
      "[167]\ttraining's auc: 0.972187\ttraining's binary_logloss: 0.363868\tvalid_1's auc: 0.870192\tvalid_1's binary_logloss: 0.437237\n",
      "[168]\ttraining's auc: 0.973437\ttraining's binary_logloss: 0.363282\tvalid_1's auc: 0.870192\tvalid_1's binary_logloss: 0.436698\n",
      "[169]\ttraining's auc: 0.973437\ttraining's binary_logloss: 0.362978\tvalid_1's auc: 0.870192\tvalid_1's binary_logloss: 0.436419\n",
      "[170]\ttraining's auc: 0.973125\ttraining's binary_logloss: 0.362205\tvalid_1's auc: 0.875\tvalid_1's binary_logloss: 0.43599\n",
      "[171]\ttraining's auc: 0.973437\ttraining's binary_logloss: 0.36148\tvalid_1's auc: 0.870192\tvalid_1's binary_logloss: 0.436138\n",
      "[172]\ttraining's auc: 0.97375\ttraining's binary_logloss: 0.360833\tvalid_1's auc: 0.875\tvalid_1's binary_logloss: 0.435835\n",
      "[173]\ttraining's auc: 0.97375\ttraining's binary_logloss: 0.360238\tvalid_1's auc: 0.875\tvalid_1's binary_logloss: 0.43614\n",
      "[174]\ttraining's auc: 0.973125\ttraining's binary_logloss: 0.359331\tvalid_1's auc: 0.875\tvalid_1's binary_logloss: 0.435798\n",
      "[175]\ttraining's auc: 0.974375\ttraining's binary_logloss: 0.358431\tvalid_1's auc: 0.870192\tvalid_1's binary_logloss: 0.435632\n",
      "[176]\ttraining's auc: 0.974375\ttraining's binary_logloss: 0.357856\tvalid_1's auc: 0.875\tvalid_1's binary_logloss: 0.435106\n",
      "[177]\ttraining's auc: 0.974063\ttraining's binary_logloss: 0.357562\tvalid_1's auc: 0.875\tvalid_1's binary_logloss: 0.434834\n",
      "[178]\ttraining's auc: 0.97375\ttraining's binary_logloss: 0.356816\tvalid_1's auc: 0.875\tvalid_1's binary_logloss: 0.434423\n",
      "[179]\ttraining's auc: 0.973437\ttraining's binary_logloss: 0.356164\tvalid_1's auc: 0.875\tvalid_1's binary_logloss: 0.434139\n",
      "[180]\ttraining's auc: 0.974375\ttraining's binary_logloss: 0.355536\tvalid_1's auc: 0.875\tvalid_1's binary_logloss: 0.433848\n",
      "[181]\ttraining's auc: 0.974375\ttraining's binary_logloss: 0.354966\tvalid_1's auc: 0.875\tvalid_1's binary_logloss: 0.434149\n",
      "[182]\ttraining's auc: 0.974063\ttraining's binary_logloss: 0.354089\tvalid_1's auc: 0.875\tvalid_1's binary_logloss: 0.433832\n",
      "[183]\ttraining's auc: 0.974375\ttraining's binary_logloss: 0.353218\tvalid_1's auc: 0.875\tvalid_1's binary_logloss: 0.433681\n",
      "[184]\ttraining's auc: 0.974688\ttraining's binary_logloss: 0.352652\tvalid_1's auc: 0.875\tvalid_1's binary_logloss: 0.433168\n",
      "[185]\ttraining's auc: 0.975\ttraining's binary_logloss: 0.352369\tvalid_1's auc: 0.875\tvalid_1's binary_logloss: 0.432904\n",
      "[186]\ttraining's auc: 0.974375\ttraining's binary_logloss: 0.35165\tvalid_1's auc: 0.875\tvalid_1's binary_logloss: 0.432512\n",
      "[187]\ttraining's auc: 0.975313\ttraining's binary_logloss: 0.350962\tvalid_1's auc: 0.875\tvalid_1's binary_logloss: 0.43268\n",
      "[188]\ttraining's auc: 0.975625\ttraining's binary_logloss: 0.350352\tvalid_1's auc: 0.875\tvalid_1's binary_logloss: 0.4324\n",
      "[189]\ttraining's auc: 0.975\ttraining's binary_logloss: 0.349803\tvalid_1's auc: 0.875\tvalid_1's binary_logloss: 0.432698\n",
      "[190]\ttraining's auc: 0.974688\ttraining's binary_logloss: 0.348955\tvalid_1's auc: 0.875\tvalid_1's binary_logloss: 0.4324\n",
      "[191]\ttraining's auc: 0.975\ttraining's binary_logloss: 0.348111\tvalid_1's auc: 0.875\tvalid_1's binary_logloss: 0.432264\n",
      "[192]\ttraining's auc: 0.975625\ttraining's binary_logloss: 0.347555\tvalid_1's auc: 0.875\tvalid_1's binary_logloss: 0.431764\n",
      "[193]\ttraining's auc: 0.975\ttraining's binary_logloss: 0.347281\tvalid_1's auc: 0.875\tvalid_1's binary_logloss: 0.431506\n",
      "[194]\ttraining's auc: 0.975313\ttraining's binary_logloss: 0.346586\tvalid_1's auc: 0.875\tvalid_1's binary_logloss: 0.431129\n",
      "[195]\ttraining's auc: 0.975\ttraining's binary_logloss: 0.345918\tvalid_1's auc: 0.875\tvalid_1's binary_logloss: 0.431304\n",
      "[196]\ttraining's auc: 0.975313\ttraining's binary_logloss: 0.345326\tvalid_1's auc: 0.875\tvalid_1's binary_logloss: 0.431035\n",
      "[197]\ttraining's auc: 0.975\ttraining's binary_logloss: 0.344797\tvalid_1's auc: 0.875\tvalid_1's binary_logloss: 0.43133\n",
      "[198]\ttraining's auc: 0.975\ttraining's binary_logloss: 0.343976\tvalid_1's auc: 0.875\tvalid_1's binary_logloss: 0.43105\n",
      "[199]\ttraining's auc: 0.975\ttraining's binary_logloss: 0.343159\tvalid_1's auc: 0.875\tvalid_1's binary_logloss: 0.430927\n",
      "[200]\ttraining's auc: 0.975938\ttraining's binary_logloss: 0.342612\tvalid_1's auc: 0.875\tvalid_1's binary_logloss: 0.430439\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(bagging_fraction=1, boosting_type='gbdt', class_weight=None,\n",
       "               colsample_bytree=1.0, feature_fraction=0.1,\n",
       "               importance_type='split', lambda_l1=0, lambda_l2=0,\n",
       "               learning_rate=0.01, max_depth=5, min_child_samples=20,\n",
       "               min_child_weight=1, min_split_gain=0.1, n_estimators=200,\n",
       "               n_jobs=20, num_leaves=24, objective=None, random_state=None,\n",
       "               reg_alpha=0.0, reg_lambda=0.0, scale_pos_weight=0.5, silent=True,\n",
       "               subsample=1.0, subsample_for_bin=200000, subsample_freq=0,\n",
       "               verbose=1)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(X_train,y_train,eval_metric =eval_metric, eval_set=eval_set, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity :  0.7\n",
      "Sensitivity :  0.9523809523809523\n",
      "Accuracy :  0.891566265060241\n",
      "Confusion Matrix : \n",
      " [ 28  12   6 120]\n"
     ]
    }
   ],
   "source": [
    "pred=model2.predict(X)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "tn, fp, fn, tp = confusion_matrix(df['SURVIVAL_STATUS'], pred,labels=[0,1]).ravel()\n",
    "cm=confusion_matrix(df['SURVIVAL_STATUS'], pred,labels=[0,1]).ravel()\n",
    "total=sum(cm)\n",
    "accuracy=(tp+tn)/(tp+tn+fn+fp)\n",
    "sensitivity = tp/(tp+fn)\n",
    "specificity = tn/(tn+fp)\n",
    "print('Specificity : ', specificity)\n",
    "print('Sensitivity : ', sensitivity )\n",
    "print ('Accuracy : ', accuracy)\n",
    "print('Confusion Matrix : \\n', cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.70      0.76        40\n",
      "           1       0.91      0.95      0.93       126\n",
      "\n",
      "    accuracy                           0.89       166\n",
      "   macro avg       0.87      0.83      0.84       166\n",
      "weighted avg       0.89      0.89      0.89       166\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 290 candidates, totalling 2900 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=50)]: Using backend LokyBackend with 50 concurrent workers.\n",
      "[Parallel(n_jobs=50)]: Done 100 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=50)]: Done 600 tasks      | elapsed:    1.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best leaf_size: 30\n",
      "Best p: 4\n",
      "Best n_neighbors: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=50)]: Done 2900 out of 2900 | elapsed:    2.3s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "#List Hyperparameters that we want to tune.\n",
    "n_neighbors = list(range(1,30))\n",
    "p=[1,2,3,4,5,6,7,8,9,10]\n",
    "#Convert to dictionary\n",
    "hyperparameters = dict( n_neighbors=n_neighbors, p=p)\n",
    "#Create new KNN object\n",
    "knn_2 = KNeighborsClassifier()\n",
    "#Use GridSearch\n",
    "clf = GridSearchCV(knn_2, hyperparameters, cv=10, n_jobs=50,verbose=1)\n",
    "#Fit the model\n",
    "best_model = clf.fit(X,y)\n",
    "#Print The value of best Hyperparameters\n",
    "print('Best leaf_size:', best_model.best_estimator_.get_params()['leaf_size'])\n",
    "print('Best p:', best_model.best_estimator_.get_params()['p'])\n",
    "print('Best n_neighbors:', best_model.best_estimator_.get_params()['n_neighbors'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(leaf_size=30, p=4, n_neighbors= 10,weights='distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=10, p=4,\n",
       "                     weights='distance')"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity :  0.925\n",
      "Sensitivity :  0.9841269841269841\n",
      "Accuracy :  0.9698795180722891\n",
      "Confusion Matrix : \n",
      " [ 37   3   2 124]\n"
     ]
    }
   ],
   "source": [
    "pred=knn.predict(X)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "tn, fp, fn, tp = confusion_matrix(df['SURVIVAL_STATUS'], pred,labels=[0,1]).ravel()\n",
    "cm=confusion_matrix(df['SURVIVAL_STATUS'], pred,labels=[0,1]).ravel()\n",
    "total=sum(cm)\n",
    "accuracy=(tp+tn)/(tp+tn+fn+fp)\n",
    "sensitivity = tp/(tp+fn)\n",
    "specificity = tn/(tn+fp)\n",
    "print('Specificity : ', specificity)\n",
    "print('Sensitivity : ', sensitivity )\n",
    "print ('Accuracy : ', accuracy)\n",
    "print('Confusion Matrix : \\n', cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9545634920634921"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(df['SURVIVAL_STATUS'], pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94        40\n",
      "           1       0.98      0.98      0.98       126\n",
      "\n",
      "    accuracy                           0.97       166\n",
      "   macro avg       0.96      0.95      0.96       166\n",
      "weighted avg       0.97      0.97      0.97       166\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |   alpha   | fit_in... |\n",
      "-------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.7148  \u001b[0m | \u001b[0m 27.89   \u001b[0m | \u001b[0m 1.423   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.7148  \u001b[0m | \u001b[0m 30.54   \u001b[0m | \u001b[0m 1.084   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.7148  \u001b[0m | \u001b[0m 21.76   \u001b[0m | \u001b[0m 1.285   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.7148  \u001b[0m | \u001b[0m 22.44   \u001b[0m | \u001b[0m 1.775   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.595   \u001b[0m | \u001b[0m 48.22   \u001b[0m | \u001b[0m 0.763   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.7131  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.99    \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.5936  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 3.117e-0\u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.7131  \u001b[0m | \u001b[0m 9.778   \u001b[0m | \u001b[0m 1.99    \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.595   \u001b[0m | \u001b[0m 39.16   \u001b[0m | \u001b[0m 0.0     \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.7131  \u001b[0m | \u001b[0m 15.82   \u001b[0m | \u001b[0m 1.99    \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.595   \u001b[0m | \u001b[0m 28.99   \u001b[0m | \u001b[0m 0.0     \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.7148  \u001b[0m | \u001b[0m 41.79   \u001b[0m | \u001b[0m 1.99    \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.7148  \u001b[0m | \u001b[0m 35.56   \u001b[0m | \u001b[0m 1.99    \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.5936  \u001b[0m | \u001b[0m 13.28   \u001b[0m | \u001b[0m 0.0     \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.7131  \u001b[0m | \u001b[0m 4.952   \u001b[0m | \u001b[0m 1.99    \u001b[0m |\n",
      "=================================================\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.linear_model import RidgeClassifier\n",
    "# develop = True\n",
    "# seed = 0\n",
    "\n",
    "    \n",
    "# def target(**params):\n",
    "#     fit_intercept = int(params['fit_intercept'])\n",
    "#     fit_intercept_dict = {0:False, 1:True}\n",
    "\n",
    "#     model = RidgeClassifier(alpha = params['alpha'],\n",
    "#                     fit_intercept = fit_intercept_dict[fit_intercept],\n",
    "#                     copy_X = True,class_weight='balanced' )\n",
    "    \n",
    "#     scores = cross_val_score(model, X_train, y_train, scoring='roc_auc', cv=5)\n",
    "#     return scores.mean()\n",
    "    \n",
    "# params = {'alpha':(1, 50),\n",
    "#           'fit_intercept':(0,1.99)}\n",
    "# if develop:\n",
    "#     bo = BayesianOptimization(target, params, random_state=seed)\n",
    "#     bo.maximize(init_points=5, n_iter=10, acq='ucb')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity :  0.85\n",
      "Sensitivity :  0.9841269841269841\n",
      "Accuracy :  0.9518072289156626\n",
      "Confusion Matrix : \n",
      " [ 34   6   2 124]\n"
     ]
    }
   ],
   "source": [
    "# ridgemodel = RidgeClassifier(alpha = 22.44,\n",
    "#                   fit_intercept = 1.45, class_weight='balanced',\n",
    "#                   copy_X = True)\n",
    "\n",
    "# ridgemodel.fit(X_train, y_train)\n",
    "# pred = ridgemodel.predict(X)\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# from sklearn.metrics import classification_report\n",
    "# tn, fp, fn, tp = confusion_matrix(df['SURVIVAL_STATUS'], pred,labels=[0,1]).ravel()\n",
    "# cm=confusion_matrix(df['SURVIVAL_STATUS'], pred,labels=[0,1]).ravel()\n",
    "# total=sum(cm)\n",
    "# accuracy=(tp+tn)/(tp+tn+fn+fp)\n",
    "# sensitivity = tp/(tp+fn)\n",
    "# specificity = tn/(tn+fp)\n",
    "# print('Specificity : ', specificity)\n",
    "# print('Sensitivity : ', sensitivity )\n",
    "# print ('Accuracy : ', accuracy)\n",
    "# print('Confusion Matrix : \\n', cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('xgb',\n",
       "                              XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                            colsample=1, colsample_bylevel=1,\n",
       "                                            colsample_bynode=1,\n",
       "                                            colsample_bytree=1, gamma=1,\n",
       "                                            learning_rate=0.01,\n",
       "                                            max_delta_step=0, max_depth=21,\n",
       "                                            min_child_weight=2, missing=None,\n",
       "                                            n_estimators=200, n_jobs=20,\n",
       "                                            nthread=None,\n",
       "                                            objective='binary:logistic',\n",
       "                                            random_state=0, reg_alpha=0.1,\n",
       "                                            reg_lambda=0.1,\n",
       "                                            scale_pos_weight=0.4, seed=None,\n",
       "                                            silent=None, subsample=1,\n",
       "                                            verbosity=1)),\n",
       "                             ('knn',\n",
       "                              KNeighborsClassifier(algorithm='auto',\n",
       "                                                   leaf_size=30,\n",
       "                                                   metric='minkowski',\n",
       "                                                   metric_params=None,\n",
       "                                                   n_jobs=None, n_neighbors=10,\n",
       "                                                   p=4, weights='distance'))],\n",
       "                 flatten_transform=True, n_jobs=None, voting='hard',\n",
       "                 weights=None)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "voting_classifier = VotingClassifier(estimators=[\n",
    "\n",
    "    ('xgb',model1), \n",
    "    ('knn', knn)],voting='hard')\n",
    "voting_classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity :  0.95\n",
      "Sensitivity :  0.9126984126984127\n",
      "Accuracy :  0.9216867469879518\n",
      "Confusion Matrix : \n",
      " [ 38   2  11 115]\n"
     ]
    }
   ],
   "source": [
    "pred=voting_classifier.predict(X)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "tn, fp, fn, tp = confusion_matrix(df['SURVIVAL_STATUS'], pred,labels=[0,1]).ravel()\n",
    "cm=confusion_matrix(df['SURVIVAL_STATUS'], pred,labels=[0,1]).ravel()\n",
    "total=sum(cm)\n",
    "accuracy=(tp+tn)/(tp+tn+fn+fp)\n",
    "sensitivity = tp/(tp+fn)\n",
    "specificity = tn/(tn+fp)\n",
    "print('Specificity : ', specificity)\n",
    "print('Sensitivity : ', sensitivity )\n",
    "print ('Accuracy : ', accuracy)\n",
    "print('Confusion Matrix : \\n', cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.90      0.78        40\n",
      "           1       0.96      0.87      0.92       126\n",
      "\n",
      "    accuracy                           0.88       166\n",
      "   macro avg       0.83      0.89      0.85       166\n",
      "weighted avg       0.90      0.88      0.88       166\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.classifier import StackingCVClassifier\n",
    "lr = LogisticRegression(C=0.1)\n",
    "sclf = StackingCVClassifier(classifiers = [lr1, randomforest, model1, knn],\n",
    "                            shuffle = False,\n",
    "                            use_probas = True,\n",
    "                            cv = 5,\n",
    "                            meta_classifier = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done   1 out of   1 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done   1 out of   1 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done   1 out of   1 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done   1 out of   1 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done   1 out of   1 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done   1 out of   1 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StackingCVClassifier(classifiers=[LogisticRegression(C=0.01,\n",
       "                                                     class_weight='balanced',\n",
       "                                                     dual=False,\n",
       "                                                     fit_intercept=True,\n",
       "                                                     intercept_scaling=1,\n",
       "                                                     l1_ratio=None,\n",
       "                                                     max_iter=300,\n",
       "                                                     multi_class='ovr',\n",
       "                                                     n_jobs=20, penalty='l2',\n",
       "                                                     random_state=None,\n",
       "                                                     solver='lbfgs', tol=0.0001,\n",
       "                                                     verbose=1,\n",
       "                                                     warm_start=False),\n",
       "                                  RandomForestClassifier(bootstrap=True,\n",
       "                                                         class_weight='balanced_subsample',\n",
       "                                                         crit...\n",
       "                                                        intercept_scaling=1,\n",
       "                                                        l1_ratio=None,\n",
       "                                                        max_iter=100,\n",
       "                                                        multi_class='warn',\n",
       "                                                        n_jobs=None,\n",
       "                                                        penalty='l2',\n",
       "                                                        random_state=None,\n",
       "                                                        solver='warn',\n",
       "                                                        tol=0.0001, verbose=0,\n",
       "                                                        warm_start=False),\n",
       "                     n_jobs=None, pre_dispatch='2*n_jobs', random_state=None,\n",
       "                     shuffle=False, store_train_meta_features=False,\n",
       "                     stratify=True, use_clones=True,\n",
       "                     use_features_in_secondary=False, use_probas=True,\n",
       "                     verbose=0)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sclf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity :  0.625\n",
      "Sensitivity :  1.0\n",
      "Accuracy :  0.9096385542168675\n",
      "Confusion Matrix : \n",
      " [ 25  15   0 126]\n"
     ]
    }
   ],
   "source": [
    "pred=sclf.predict(X)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "tn, fp, fn, tp = confusion_matrix(df['SURVIVAL_STATUS'], pred,labels=[0,1]).ravel()\n",
    "cm=confusion_matrix(df['SURVIVAL_STATUS'], pred,labels=[0,1]).ravel()\n",
    "total=sum(cm)\n",
    "accuracy=(tp+tn)/(tp+tn+fn+fp)\n",
    "sensitivity = tp/(tp+fn)\n",
    "specificity = tn/(tn+fp)\n",
    "print('Specificity : ', specificity)\n",
    "print('Sensitivity : ', sensitivity )\n",
    "print ('Accuracy : ', accuracy)\n",
    "print('Confusion Matrix : \\n', cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8125"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(df['SURVIVAL_STATUS'], pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.62      0.77        40\n",
      "           1       0.89      1.00      0.94       126\n",
      "\n",
      "    accuracy                           0.91       166\n",
      "   macro avg       0.95      0.81      0.86       166\n",
      "weighted avg       0.92      0.91      0.90       166\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
